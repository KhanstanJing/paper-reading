# I-2018-2019年中

## 甲：Inst Disc

## 乙：preSimCLR

## 丙：CPC

“用预测的代理任务做对比学习”

### 壹：什么是CPC

首先CPC是一个算法，它提出了一种学习的架构，里面的组成部件没有硬性要求，换言之，它是一种**如何安排部件的方法**

### 贰：CPC靠什么实现

这种算法要用到**一个编码器**和**一个自回归模型**，有了这两个东西之后就可以开始用这种算法进行无监督学习了，学习过程中需要优化一个作者提出的叫做InfoNCE的损失

### 叁：CPC的优势

根据作者在文中的描述，该算法的优势在于普遍性（universal），普遍性在于两点，第一是它对于其中的编码器和自回归模型没有要求；第二是它对于原始数据没有要求，作者称可以对于语音、图像、文本和强化学习这四个领域处理

### 肆：CPC的创新点

作者在文中首先论述了之前方法的不足之处与存在的挑战，而后论述了他的创新点

#### 一、预测高维数据中的挑战

在预测高维数据的过程中，以往的单峰损失，类似于均方误差和交叉熵没有用了

#### 二、对于生成模型的要求

在以往的方法中，我们需要条件生成模型去**重建**数据中的**每一处**细节（作者的意思应该是原先方法中是需要重建数据以和原数据进行对比而后计算损失，进行优化，从而达到学习的效果），但是这样我们就需要特别强大的生成模型，这个工作是计算密集型（“computationally intense”）的，并且在建模原始数据中的复杂关系时会浪费承载力（capacity），且会忽略上下文

总之就是之前的方法是学习-对比-优化损失（减少不同之处）-学习，但是这个过程非常复杂且产生大量的浪费

#### 三、损失函数的创新

因此，作者提出了一个与其上面的算法过程对应的损失函数，这种损失函数并不单单注重计算不同，而是旨在提取出交互信息（mutual infomation），这个目的是让模型能够学习到更高维度的特征，模型首先不必对于每一个细节进行重建，而是只对于其提取出来的特征进行重建，另外我推测计算交互信息这一步骤解决了单峰损失失效的问题

### 伍：CPC具体的实现细节

#### 一、编码器对于原始数据进行特征提取

这个时候原始数据被分成很多子部分，在原文中用的可能是一段语音数据

语音数据被分成很多小段，每一个小段被喂给编码器，编码器进行特征提取

#### 二、自回归模型结合特征进行预测

首先，之前的特征提取是同时进行的，不涉及顺序，即同时分段后喂给编码器

但是这里的自回归模型预测有顺序的要求，当自回归模型开始吃第$t$个小段$x_t$提取出的特征$z_t$的时候，它还吃了第$t-1$个小段提取出特征后经过自回归模型后吐出来的预测$c_{t-1}$，有一点递归的思想，这样就能把过去的信息和预测与现在的信息结合在一起

随后，自回归模型吐出在$t$小段的预测$c_t$

#### 三、编码器和自回归模型的损失函数

损失函数的结构表明了模型的优化方向，在这里作者采用的是基于NCE的一种函数，其将该函数命名为InfoNCE，这个函数在附录部分有详细的推导，在这里只要知道优化这个损失函数的时候，我们在最大化由第$t$个小段$z_t$中提取出的特征$z_t$和之前的预测$c_{t-1}$共同产生的预测$c_t$和后面的特征的交互信息（mutual information）即可

作者提到，这个损失函数的特点是样本越大越好

## 丁：CMC

# II-2019年中-2020年中

# III-2020-不用负样本的对比学习

# IV-2021-Transformer时代
