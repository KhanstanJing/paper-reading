https://voidful.dev/2020/06/28/2020-06-28-paper-notes-simclr/
https://amitness.com/2020/03/illustrated-simclr/
# A Simple Framework for Contrastive Learning of Visual Representations
重点放在学习表示上

方法：
一张图片，对该图片进行两次分别的增强，这两张图片都为正样本
同一批次中其他图片的所有增强为负样本
计算正负样本的损失，让一张图片的判断为同一张，不同图片的判断为不同

技巧：
数据增强：
同一张图片，在进行数据增强的时候，采用两种增强效果好
并且作者给出了实验数据佐证，并且说明了增强效果最好的是Crop和Colour同时用
向量投影：
使用ResNet-50学，学出来的2048维向量投影后再进行loss值计算
作者这么做的原因是认为投影后的特征会混在一起，增大学习难度，提高学习效果
而后使用实验佐证了这个结论
更进一步地，作者还论证了投影向量的维度的关系，做了实验
结论是输出的维度大小不影响学习效果，且非线性映射比线性映射效果好
批次大小：
没有办法再整个数据集上设置正负样本的loss计算，因为太大了
因此设置批次，每一个批次中的图像经过增强后整个批次中的图像进行loss值计算
并且作者做实验论证了批次大小影响学习效果，给出了图像，大到一定程度后效果增长速度变慢
（训练中用不同批次不同轮次）